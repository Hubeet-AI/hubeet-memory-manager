# Hubeet Memory ‚Äì Subsistema de Memoria Sem√°ntica Jer√°rquica

Repositorio oficial del subsistema de memoria para LLMs utilizado en el ecosistema de Hubeet. Este sistema permite almacenar, recuperar y evolucionar recuerdos de manera inteligente, estructurada y escalable.

---


## ¬øQu√© es esto?

`hubeet-memory-manager` es una arquitectura de memoria vectorial contextual con:

- Compresi√≥n sem√°ntica
- Recuperaci√≥n jer√°rquica
- Atenci√≥n negativa (recuerda qu√© ignorar)
- Penalizaci√≥n y despenalizaci√≥n din√°mica de recuerdos

Todo esto usando PostgreSQL con `pgvector`, embeddings modernos y Node.js/NestJS.

Ac√° ten√©s una secci√≥n introductoria simple, con ejemplos cotidianos y analog√≠as con el funcionamiento del cerebro humano:

‚∏ª

### ¬øQu√© intenta hacer este sistema? ‚Äî Explicaci√≥n para humanos

Imagin√° que tu cerebro fuera una computadora, y cada vez que quer√©s recordar algo, ten√©s que revisar todos tus recuerdos, sin saber cu√°les son relevantes. Ser√≠a agotador. Por eso tu mente filtra, resume, ignora y abstrae.

Eso mismo estamos replicando ac√°:
un sistema de memoria que piensa como vos.

‚∏ª

### Ejemplo 1 ‚Äì El bar y el mozo

Vas siempre al mismo bar. El mozo no recuerda cada palabra que le dijiste en todas tus visitas. Solo recuerda lo importante:

‚ÄúCaf√© cortado, sin az√∫car, con medialuna.‚Äù

Eso es compresi√≥n sem√°ntica: recordar lo √∫til, no todo.

‚∏ª

### Ejemplo 2 ‚Äì Ignorar lo in√∫til

Tu cerebro ignora autom√°ticamente cosas como:
	‚Ä¢	La marca de la servilleta
	‚Ä¢	La m√∫sica de fondo si no te importa

Ac√° hacemos lo mismo: los recuerdos irrelevantes se penalizan y bajan en el ranking.

‚∏ª

### Ejemplo 3 ‚Äì Pensar por capas

Cuando alguien te pregunta ‚Äú¬øQu√© hiciste hoy?‚Äù, no respond√©s con cada microacci√≥n. Primero das un resumen:
‚ÄúTrabaj√© toda la ma√±ana, fui al gimnasio y cen√© con amigos.‚Äù
Solo si te preguntan m√°s, baj√°s al detalle.
Eso es una memoria jer√°rquica. Primero lo abstracto. Luego el detalle si hace falta.

‚∏ª

Este sistema hace eso, pero para m√°quinas. Les da capacidad de olvidar, priorizar y resumir, para que puedan pensar mejor y m√°s r√°pido.

---

## Caracter√≠sticas Clave

| M√≥dulo                          | Funci√≥n                                                                 |
|-------------------------------|------------------------------------------------------------------------|
| `MemoryService`               | Interfaz principal para guardar/recuperar texto                        |
| `VectorIndex`                 | Gesti√≥n de almacenamiento/b√∫squeda en pgvector                         |
| `MemorySelector`              | Recuperaci√≥n inteligente con penalizaci√≥n, revalorizaci√≥n y jerarqu√≠a  |
| `buildContextEmbedding`       | Arma un embedding sem√°ntico de la situaci√≥n actual                    |
| `compressNodes`               | Crea un nodo resumen con embeddings promediados                        |

---

## Instalaci√≥n

```bash
git clone https://github.com/solunika/hubeet-memory.git
cd hubeet-memory
npm install
```

### Prerrequisitos
- PostgreSQL + extensi√≥n `pgvector`
- Tabla `memory_nodes` con los campos:
```sql
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE memory_nodes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  memory_id TEXT,
  text_original TEXT,
  embedding VECTOR(1536),
  version_tag INTEGER DEFAULT 1,
  updated_at TIMESTAMP DEFAULT NOW(),
  ignore_score REAL DEFAULT 0,
  layer INTEGER DEFAULT 0,
  source_ids TEXT[]
);
```

---

## Ejemplo de uso b√°sico

```ts
await memoryService.createNode("La memoria sem√°ntica mejora la comprensi√≥n contextual", "soporte-123");
```

```ts
await memorySelector.retrieveRelevantMemories({
  query: "¬øQu√© ventajas tiene usar memoria vectorial?",
  memoryId: "soporte-123",
  userIntent: "explicar ventajas",
  tags: ["llm", "contexto"],
  debug: true
});
```

Resultado:
```ts
[
  { id: "n1", similarity: 0.91, layer: 0, text_original: "La memoria sem√°ntica..." },
  { id: "n2", similarity: 0.87, layer: 1, text_original: "Resumen de 5 ideas sobre..." }
]
```

---

## Propuestas implementadas

### 10. Modelos que Recuerdan Qu√© Ignorar

- Cada recuerdo tiene un `ignore_score`
- Si es descartado, se penaliza (sube)
- Si se vuelve a usar, se recompensa (baja)
- Se ajusta el ranking en la b√∫squeda: `similaridad + penalizaci√≥n`

### 9. Red de Compresi√≥n Sem√°ntica Jer√°rquica

- Se pueden agrupar varios recuerdos (`layer = 0`) y generar un resumen (`layer = 1`)
- Esto permite razonamiento m√°s r√°pido y menos costoso

```ts
await vectorIndex.compressNodes({
  nodes: [nodo1, nodo2, nodo3],
  memoryId: "soporte-123"
});
```

---

## Debug + Audit Trail (opcional)

Us√° `debug: true` en cualquier llamada a `retrieveRelevantMemories(...)` para ver el contexto generado antes del embedding.

```ts
// Output en consola:
üîç Contexto generado para embedding:
INTENCI√ìN DEL USUARIO: explicar ventajas
PREGUNTA: ¬øQu√© ventajas tiene usar memoria vectorial?
TAGS: llm, contexto
```

---

## Glosario

- `embedding`: vector num√©rico que representa sem√°nticamente un texto.
- `layer`: nivel jer√°rquico del recuerdo (0 = detalle, 1 = resumen).
- `ignore_score`: penalizaci√≥n acumulada si un nodo no resulta √∫til.
- `context embedding`: vector generado del estado actual para buscar.
- `selector`: m√≥dulo que decide qu√© recuerdos traer.

---

## Futuro

- UI para explorar la red de recuerdos
- Rutas de expansi√≥n contextual progresiva
- Integraci√≥n con agentes aut√≥nomos Hubeet

---

Hecho con cari√±o por el equipo de **Hubeet**.